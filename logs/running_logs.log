[2024-11-01 19:28:02,499: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/middleman "HTTP/1.1 408 Request Timeout"]
[2024-11-01 19:31:46,381: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/middleman "HTTP/1.1 200 OK"]
[2024-11-01 19:31:47,695: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/access_token "HTTP/1.1 200 OK"]
[2024-11-01 19:31:48,996: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 19:31:48,996: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 19:31:50,071: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 19:31:50,086: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 19:31:50,091: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 19:31:50,091: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 19:31:50,099: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 19:31:50,109: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 19:31:50,113: INFO: common: created directory at: artifacts]
[2024-11-01 19:31:50,115: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 19:31:50,115: ERROR: main: "'ConfigBox' object has no attribute 'source_url'"]
Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: 'source_URL'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'source_URL'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'source_URL'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\config_box.py", line 28, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'source_URL'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 503, in box.box.Box.__getitem__
KeyError: 'source_url'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\box.py", line 536, in box.box.Box.__getattr__
  File "box\box.py", line 524, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'source_url'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\box.py", line 538, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'source_url'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 14, in main
    data_ingestion_config = config.get_data_ingestion_config()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 29, in get_data_ingestion_config
    source_URL=config.source_URL,
  File "box\config_box.py", line 30, in box.config_box.ConfigBox.__getattr__
  File "box\box.py", line 552, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'source_url'"
[2024-11-01 19:46:59,997: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 19:47:00,067: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 19:47:01,426: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 19:47:01,434: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 19:47:01,436: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 19:47:01,436: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 19:47:01,436: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 19:47:01,441: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 19:47:01,441: INFO: common: created directory at: artifacts]
[2024-11-01 19:47:01,441: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 19:47:01,441: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 14, in main
    data_ingestion_config = config.get_data_ingestion_config()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 27, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 19:51:31,766: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 19:51:31,775: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 19:51:32,990: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 19:51:32,997: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 19:51:32,997: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 19:51:32,997: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 19:51:33,006: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 19:51:33,008: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 19:51:33,008: INFO: common: created directory at: artifacts]
[2024-11-01 19:51:33,008: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 19:51:33,008: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 13, in <module>
    data_ingestion = DataIngestionTrainingPipeline()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 9, in __init__
    self.config = ConfigurationManager().get_data_ingestion_config()  # Ambil konfigurasi saat inisialisasi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 26, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 19:54:29,116: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 19:54:29,131: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 19:54:30,036: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 19:54:30,046: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 19:54:30,046: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 19:54:30,046: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 19:54:30,051: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 19:54:30,051: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 19:54:30,051: INFO: common: created directory at: artifacts]
[2024-11-01 19:54:30,051: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 19:54:30,051: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 13, in <module>
    data_ingestion = DataIngestionTrainingPipeline()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 9, in __init__
    self.config = ConfigurationManager().get_data_ingestion_config()  # Ambil konfigurasi saat inisialisasi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 26, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 20:01:10,636: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:01:10,649: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:01:11,650: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:01:11,656: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:01:11,656: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:01:11,661: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:01:11,661: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:01:11,666: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:01:11,666: INFO: common: created directory at: artifacts]
[2024-11-01 20:01:11,666: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:01:11,670: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 13, in <module>
    data_ingestion = DataIngestionTrainingPipeline()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 9, in __init__
    self.config = ConfigurationManager().get_data_ingestion_config()  # Ambil konfigurasi saat inisialisasi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 26, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 20:03:52,016: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:03:52,016: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:03:53,036: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:03:53,039: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:03:53,039: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:03:53,039: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:03:53,046: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:03:53,046: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:03:53,046: INFO: common: created directory at: artifacts]
[2024-11-01 20:03:53,046: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:03:53,046: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 13, in <module>
    data_ingestion = DataIngestionTrainingPipeline()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 9, in __init__
    self.config = ConfigurationManager().get_data_ingestion_config()  # Ambil konfigurasi saat inisialisasi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 26, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 20:06:50,418: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:06:50,436: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:06:51,176: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:06:51,186: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:06:51,189: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:06:51,189: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:06:51,189: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:06:51,189: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:06:51,189: INFO: common: created directory at: artifacts]
[2024-11-01 20:06:51,189: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:06:51,189: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinson_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 37, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinson_dataset.zip'
[2024-11-01 20:12:09,166: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:12:09,191: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:12:10,697: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:12:10,706: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:12:10,711: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:12:10,711: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:12:10,719: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:12:10,719: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:12:10,719: INFO: common: created directory at: artifacts]
[2024-11-01 20:12:10,729: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:12:10,729: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\data.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 37, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\data.zip'
[2024-11-01 20:13:46,951: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:13:46,990: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:13:48,698: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:13:48,708: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:13:48,708: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:13:48,708: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:13:48,714: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:13:48,716: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:13:48,719: INFO: common: created directory at: artifacts]
[2024-11-01 20:13:48,719: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:13:48,719: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 37, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip'
[2024-11-01 20:20:06,046: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:20:06,103: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:20:07,676: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:20:07,680: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:20:07,686: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:20:07,686: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:20:07,691: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:20:07,691: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:20:07,691: INFO: common: created directory at: artifacts]
[2024-11-01 20:20:07,696: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:20:07,696: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 13, in <module>
    data_ingestion = DataIngestionTrainingPipeline()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 9, in __init__
    self.config = ConfigurationManager().get_data_ingestion_config()  # Ambil konfigurasi saat inisialisasi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 26, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 20:20:58,571: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:20:58,591: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:21:00,406: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:21:00,421: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:21:00,421: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:21:00,421: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:21:00,426: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:21:00,431: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:21:00,432: INFO: common: created directory at: artifacts]
[2024-11-01 20:21:00,432: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:21:00,432: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 43, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip'
[2024-11-01 20:26:31,216: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:26:31,277: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:26:32,816: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:26:32,822: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:26:32,828: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:26:32,828: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:26:32,830: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:26:32,838: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:26:32,838: INFO: common: created directory at: artifacts]
[2024-11-01 20:26:32,844: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:26:32,848: ERROR: main: __init__() missing 1 required positional argument: 'source_local_file']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 13, in <module>
    data_ingestion = DataIngestionTrainingPipeline()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 9, in __init__
    self.config = ConfigurationManager().get_data_ingestion_config()  # Ambil konfigurasi saat inisialisasi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\config\configuration.py", line 26, in get_data_ingestion_config
    data_ingestion_config = DataIngestionConfig(
TypeError: __init__() missing 1 required positional argument: 'source_local_file'
[2024-11-01 20:28:32,914: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:28:32,953: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:28:34,452: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:28:34,452: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:28:34,452: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:28:34,452: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:28:34,452: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:28:34,467: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:28:34,467: INFO: common: created directory at: artifacts]
[2024-11-01 20:28:34,467: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:28:34,467: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 43, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip'
[2024-11-01 20:31:42,151: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-01 20:31:42,202: INFO: helpers: Accessing as khalfaqi]
[2024-11-01 20:31:43,787: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-01 20:31:43,795: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-01 20:31:43,803: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-01 20:31:43,803: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-01 20:31:43,803: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-01 20:31:43,810: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-01 20:31:43,816: INFO: common: created directory at: artifacts]
[2024-11-01 20:31:43,819: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-01 20:31:43,819: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 41, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip'
[2024-11-02 10:34:59,221: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 502 Bad Gateway"]
[2024-11-02 10:35:00,547: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/middleman "HTTP/1.1 502 Bad Gateway"]
[2024-11-02 10:55:12,647: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-02 10:55:12,666: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-02 10:55:12,668: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-02 10:55:12,668: INFO: common: created directory at: artifacts]
[2024-11-02 10:55:12,668: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-02 10:55:12,668: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 14, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 36, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip'
[2024-11-02 11:04:20,717: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/middleman "HTTP/1.1 502 Bad Gateway"]
[2024-11-02 20:30:06,522: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/middleman "HTTP/1.1 200 OK"]
[2024-11-02 20:30:07,882: INFO: _client: HTTP Request: POST https://dagshub.com/login/oauth/access_token "HTTP/1.1 200 OK"]
[2024-11-02 20:30:09,004: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-02 20:30:09,011: INFO: helpers: Accessing as khalfaqi]
[2024-11-02 20:30:10,127: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-02 20:30:10,144: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-02 20:30:10,144: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-02 20:30:10,144: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-02 20:30:10,158: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-02 20:30:10,191: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-02 20:30:10,195: INFO: common: created directory at: artifacts]
[2024-11-02 20:30:10,196: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-02 20:30:10,197: ERROR: main: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip']
Traceback (most recent call last):
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\main.py", line 12, in <module>
    data_ingestion.main()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\pipeline_data_ingestion.py", line 13, in main
    data_ingestion.extract_zip_file()  # Menyesuaikan jika Anda tidak perlu mendownload file lagi
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\components\data_ingestion.py", line 36, in extract_zip_file
    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\zipfile.py", line 1250, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\parkinsons_dataset.zip'
[2024-11-02 20:33:30,889: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-02 20:33:30,904: INFO: helpers: Accessing as khalfaqi]
[2024-11-02 20:33:32,135: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-02 20:33:32,151: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-02 20:33:32,151: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-02 20:33:32,151: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-02 20:33:32,151: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-02 20:33:32,167: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-02 20:33:32,167: INFO: common: created directory at: artifacts]
[2024-11-02 20:33:32,167: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-02 20:33:32,781: INFO: data_ingestion: Extracted artifacts\data_ingestion\parkinsons_dataset.zip to artifacts\data_ingestion]
[2024-11-02 20:33:32,781: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2024-11-02 20:33:32,781: INFO: main: *******************]
[2024-11-02 20:33:32,781: INFO: main: >>>>>> stage Prepare base model started <<<<<<]
[2024-11-02 20:33:32,799: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-02 20:33:32,808: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-02 20:33:32,810: INFO: common: created directory at: artifacts]
[2024-11-02 20:33:32,818: INFO: common: created directory at: artifacts/prepare_base_model]
[2024-11-02 20:37:06,671: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]
[2024-11-02 20:37:07,070: INFO: main: >>>>>> stage Prepare base model completed <<<<<<

x==========x]
[2024-11-02 20:37:07,070: INFO: main: *******************]
[2024-11-02 20:37:07,070: INFO: main: >>>>>> stage Training started <<<<<<]
[2024-11-02 20:37:07,081: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-02 20:37:07,084: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-02 20:37:07,085: INFO: common: created directory at: artifacts]
[2024-11-02 20:37:07,085: INFO: common: created directory at: artifacts\training]
[2024-11-02 20:54:51,089: INFO: main: >>>>>> stage Training completed <<<<<<

x==========x]
[2024-11-02 20:54:51,089: INFO: main: *******************]
[2024-11-02 20:54:51,089: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]
[2024-11-02 20:54:51,089: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-02 20:54:51,089: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-02 20:54:51,089: INFO: common: created directory at: artifacts]
[2024-11-02 20:55:28,434: INFO: common: json file saved at: scores.json]
[2024-11-02 20:55:28,434: INFO: common: json file saved at: scores.json]
[2024-11-02 20:55:28,434: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<

x==========x]
[2024-11-03 11:33:49,777: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-03 11:33:49,793: INFO: helpers: Accessing as khalfaqi]
[2024-11-03 11:33:51,654: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-03 11:33:51,663: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-03 11:33:51,667: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-03 11:33:51,668: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-03 11:33:51,676: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-03 11:33:51,719: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-03 11:33:51,723: INFO: common: created directory at: artifacts]
[2024-11-03 11:33:51,726: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-03 11:33:53,838: INFO: data_ingestion: Extracted artifacts\data_ingestion\parkinsons_dataset.zip to artifacts\data_ingestion]
[2024-11-03 11:33:53,838: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2024-11-03 11:33:53,840: INFO: main: *******************]
[2024-11-03 11:33:53,840: INFO: main: >>>>>> stage Prepare base model started <<<<<<]
[2024-11-03 11:33:53,844: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-03 11:33:53,855: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-03 11:33:53,855: INFO: common: created directory at: artifacts]
[2024-11-03 11:33:53,855: INFO: common: created directory at: artifacts/prepare_base_model]
[2024-11-03 11:33:55,781: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]
[2024-11-03 11:33:56,554: INFO: main: >>>>>> stage Prepare base model completed <<<<<<

x==========x]
[2024-11-03 11:33:56,554: INFO: main: *******************]
[2024-11-03 11:33:56,557: INFO: main: >>>>>> stage Training started <<<<<<]
[2024-11-03 11:33:56,563: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-03 11:33:56,570: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-03 11:33:56,573: INFO: common: created directory at: artifacts]
[2024-11-03 11:33:56,573: INFO: common: created directory at: artifacts\training]
[2024-11-03 11:56:07,645: INFO: main: >>>>>> stage Training completed <<<<<<

x==========x]
[2024-11-03 11:56:07,650: INFO: main: *******************]
[2024-11-03 11:56:07,650: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]
[2024-11-03 11:56:07,652: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-03 11:56:07,660: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-03 11:56:07,660: INFO: common: created directory at: artifacts]
[2024-11-03 11:57:26,113: INFO: common: json file saved at: scores.json]
[2024-11-03 11:57:26,114: INFO: common: json file saved at: scores.json]
[2024-11-03 11:57:26,114: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<

x==========x]
[2024-11-04 12:11:45,139: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-04 12:11:45,163: INFO: helpers: Accessing as khalfaqi]
[2024-11-04 12:11:46,759: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-04 12:11:46,793: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-04 12:11:46,795: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-04 12:11:46,795: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-04 12:11:46,810: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:11:46,825: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:11:46,826: INFO: common: created directory at: artifacts]
[2024-11-04 12:11:46,826: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-04 12:11:47,705: INFO: data_ingestion: Extracted artifacts\data_ingestion\parkinsons_dataset.zip to artifacts\data_ingestion]
[2024-11-04 12:11:47,705: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2024-11-04 12:11:47,707: INFO: main: *******************]
[2024-11-04 12:11:47,708: INFO: main: >>>>>> stage Prepare base model started <<<<<<]
[2024-11-04 12:11:47,709: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:11:47,712: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:11:47,712: INFO: common: created directory at: artifacts]
[2024-11-04 12:11:47,713: INFO: common: created directory at: artifacts/prepare_base_model]
[2024-11-04 12:11:48,858: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]
[2024-11-04 12:11:49,390: INFO: main: >>>>>> stage Prepare base model completed <<<<<<

x==========x]
[2024-11-04 12:11:49,390: INFO: main: *******************]
[2024-11-04 12:11:49,390: INFO: main: >>>>>> stage Training started <<<<<<]
[2024-11-04 12:11:49,394: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:11:49,394: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:11:49,394: INFO: common: created directory at: artifacts]
[2024-11-04 12:11:49,394: INFO: common: created directory at: artifacts\training]
[2024-11-04 12:25:44,293: INFO: main: >>>>>> stage Training completed <<<<<<

x==========x]
[2024-11-04 12:25:44,293: INFO: main: *******************]
[2024-11-04 12:25:44,293: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]
[2024-11-04 12:25:44,300: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:25:44,313: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:25:44,313: INFO: common: created directory at: artifacts]
[2024-11-04 12:26:17,420: INFO: common: json file saved at: scores.json]
[2024-11-04 12:26:17,420: INFO: common: json file saved at: scores.json]
[2024-11-04 12:26:17,420: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<

x==========x]
[2024-11-04 12:40:29,232: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-04 12:40:29,253: INFO: helpers: Accessing as khalfaqi]
[2024-11-04 12:40:30,254: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-04 12:40:30,254: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-04 12:40:30,254: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-04 12:40:30,254: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-04 12:40:30,270: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:40:30,282: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:40:30,282: INFO: common: created directory at: artifacts]
[2024-11-04 12:40:30,282: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-04 12:40:30,718: INFO: data_ingestion: Extracted artifacts\data_ingestion\parkinsons_dataset.zip to artifacts\data_ingestion]
[2024-11-04 12:40:30,733: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2024-11-04 12:40:30,733: INFO: main: *******************]
[2024-11-04 12:40:30,733: INFO: main: >>>>>> stage Prepare base model started <<<<<<]
[2024-11-04 12:40:30,733: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:40:30,733: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:40:30,733: INFO: common: created directory at: artifacts]
[2024-11-04 12:40:30,733: INFO: common: created directory at: artifacts/prepare_base_model]
[2024-11-04 12:40:31,240: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]
[2024-11-04 12:40:31,483: INFO: main: >>>>>> stage Prepare base model completed <<<<<<

x==========x]
[2024-11-04 12:40:31,483: INFO: main: *******************]
[2024-11-04 12:40:31,483: INFO: main: >>>>>> stage Training started <<<<<<]
[2024-11-04 12:40:31,483: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:40:31,483: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:40:31,483: INFO: common: created directory at: artifacts]
[2024-11-04 12:40:31,483: INFO: common: created directory at: artifacts\training]
[2024-11-04 12:50:38,771: INFO: main: >>>>>> stage Training completed <<<<<<

x==========x]
[2024-11-04 12:50:38,771: INFO: main: *******************]
[2024-11-04 12:50:38,771: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]
[2024-11-04 12:50:38,771: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-04 12:50:38,771: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-04 12:50:38,771: INFO: common: created directory at: artifacts]
[2024-11-04 12:51:04,004: INFO: common: json file saved at: scores.json]
[2024-11-04 12:51:04,004: INFO: common: json file saved at: scores.json]
[2024-11-04 12:51:07,087: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]
[2024-11-04 12:51:07,625: INFO: builder_impl: Assets written to: C:\Users\Haura\AppData\Local\Temp\tmpcwr9y39k\model\data\model\assets]
[2024-11-04 12:55:44,580: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<

x==========x]
[2024-11-06 11:42:42,726: INFO: pipeline_data_ingestion: >>>>>> stage Data Ingestion stage started <<<<<<]
[2024-11-06 11:42:42,736: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-06 11:42:42,736: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-06 11:42:42,736: INFO: common: created directory at: artifacts]
[2024-11-06 11:42:42,736: INFO: common: created directory at: artifacts/data_ingestion]
[2024-11-06 11:42:43,390: INFO: data_ingestion: Extracted artifacts\data_ingestion\parkinsons_dataset.zip to artifacts\data_ingestion]
[2024-11-06 11:42:43,390: INFO: pipeline_data_ingestion: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2024-11-06 11:43:05,350: INFO: pipeline_prepare_base_model: *******************]
[2024-11-06 11:43:05,350: INFO: pipeline_prepare_base_model: >>>>>> stage Prepare base model started <<<<<<]
[2024-11-06 11:43:05,350: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-06 11:43:05,350: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-06 11:43:05,350: INFO: common: created directory at: artifacts]
[2024-11-06 11:43:05,356: INFO: common: created directory at: artifacts/prepare_base_model]
[2024-11-06 11:43:06,220: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]
[2024-11-06 11:43:06,563: INFO: pipeline_prepare_base_model: >>>>>> stage Prepare base model completed <<<<<<

x==========x]
[2024-11-06 11:43:13,811: INFO: pipeline_model_training: *******************]
[2024-11-06 11:43:13,817: INFO: pipeline_model_training: >>>>>> stage Training started <<<<<<]
[2024-11-06 11:43:13,817: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-06 11:43:13,820: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-06 11:43:13,820: INFO: common: created directory at: artifacts]
[2024-11-06 11:43:13,820: INFO: common: created directory at: artifacts\training]
[2024-11-06 11:55:48,837: INFO: pipeline_model_training: >>>>>> stage Training completed <<<<<<

x==========x]
[2024-11-06 11:56:01,240: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-06 11:56:01,260: INFO: helpers: Accessing as khalfaqi]
[2024-11-06 11:56:02,362: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-06 11:56:02,367: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-06 11:56:02,367: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-06 11:56:02,367: INFO: pipeline_model_evaluation: *******************]
[2024-11-06 11:56:02,367: INFO: pipeline_model_evaluation: >>>>>> stage Evaluation stage started <<<<<<]
[2024-11-06 11:56:02,375: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-06 11:56:02,378: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-06 11:56:02,378: INFO: common: created directory at: artifacts]
[2024-11-06 11:56:38,661: INFO: common: json file saved at: scores.json]
[2024-11-06 11:56:38,664: INFO: common: json file saved at: scores.json]
[2024-11-06 11:56:43,231: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]
[2024-11-06 11:56:44,094: INFO: builder_impl: Assets written to: C:\Users\Haura\AppData\Local\Temp\tmp53i3m2y3\model\data\model\assets]
[2024-11-06 12:01:15,576: INFO: pipeline_model_evaluation: >>>>>> stage Evaluation stage completed <<<<<<

x==========x]
[2024-11-10 22:05:13,701: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"]
[2024-11-10 22:05:13,722: INFO: helpers: Accessing as khalfaqi]
[2024-11-10 22:05:14,522: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/khalfaqi/Parkinson-Detection "HTTP/1.1 200 OK"]
[2024-11-10 22:05:14,525: INFO: helpers: Initialized MLflow to track repo "khalfaqi/Parkinson-Detection"]
[2024-11-10 22:05:14,525: INFO: helpers: Repository khalfaqi/Parkinson-Detection initialized!]
[2024-11-10 22:05:14,525: INFO: pipeline_model_evaluation: *******************]
[2024-11-10 22:05:14,525: INFO: pipeline_model_evaluation: >>>>>> stage Evaluation stage started <<<<<<]
[2024-11-10 22:05:14,525: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-11-10 22:05:14,549: INFO: common: yaml file: params.yaml loaded successfully]
[2024-11-10 22:05:14,568: INFO: common: created directory at: artifacts]
[2024-11-10 22:05:49,252: INFO: common: json file saved at: scores.json]
[2024-11-10 22:05:49,255: INFO: common: json file saved at: scores.json]
[2024-11-10 22:05:49,255: INFO: pipeline_model_evaluation: >>>>>> stage Evaluation stage completed <<<<<<

x==========x]
[2024-11-10 22:21:58,098: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 22:21:58,098: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 22:22:51,120: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:22:51] "GET / HTTP/1.1" 200 -]
[2024-11-10 22:22:51,169: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:22:51] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -]
[2024-11-10 22:24:03,363: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 22:24:03,363: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 22:24:09,284: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:24:09] "GET / HTTP/1.1" 200 -]
[2024-11-10 22:24:32,471: ERROR: app: Exception on /predict [POST]]
Traceback (most recent call last):
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask_cors\extension.py", line 194, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask_cors\decorator.py", line 130, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\apps.py", line 39, in predictRoute
    result = clApp.classifier.predict()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\prediction.py", line 15, in predict
    model = load_model(os.path.join("model", "model.h5"))
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\keras\saving\saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\keras\saving\legacy\save.py", line 230, in load_model
    raise IOError(
OSError: No file or directory found at model\model.h5
[2024-11-10 22:24:32,481: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:24:32] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -]
[2024-11-10 22:29:42,696: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 22:29:42,696: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 22:29:55,133: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:29:55] "GET / HTTP/1.1" 200 -]
[2024-11-10 22:30:04,719: ERROR: app: Exception on /predict [POST]]
Traceback (most recent call last):
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask_cors\extension.py", line 194, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\flask_cors\decorator.py", line 130, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "C:\Users\Haura\Documents\Parkinson Detection\Parkinson-Detection\apps.py", line 39, in predictRoute
    result = clApp.classifier.predict()
  File "c:\users\haura\documents\parkinson detection\parkinson-detection\src\ParkinsonClassification\pipeline\prediction.py", line 15, in predict
    model = load_model(os.path.join("model", "model.h5"))
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\keras\saving\saving_api.py", line 212, in load_model
    return legacy_sm_saving_lib.load_model(
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "C:\Users\Haura\miniconda3\envs\parkinson\lib\site-packages\keras\saving\legacy\save.py", line 230, in load_model
    raise IOError(
OSError: No file or directory found at model\model.h5
[2024-11-10 22:30:04,734: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:30:04] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -]
[2024-11-10 22:41:39,224: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 22:41:39,228: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 22:41:46,450: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:41:46] "GET / HTTP/1.1" 200 -]
[2024-11-10 22:42:00,770: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:42:00] "POST /predict HTTP/1.1" 200 -]
[2024-11-10 22:42:18,234: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 22:42:18] "POST /predict HTTP/1.1" 200 -]
[2024-11-10 23:09:15,261: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 23:09:15,261: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 23:09:30,031: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 23:09:30] "GET / HTTP/1.1" 200 -]
[2024-11-10 23:11:04,874: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 23:11:04,874: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 23:11:07,431: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 23:11:07] "GET / HTTP/1.1" 200 -]
[2024-11-10 23:11:09,103: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 23:11:09] "GET / HTTP/1.1" 200 -]
[2024-11-10 23:13:44,657: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 23:13:44,657: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 23:13:51,998: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 23:13:51] "GET / HTTP/1.1" 200 -]
[2024-11-10 23:14:01,480: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 23:14:01] "[31m[1mPOST /predict HTTP/1.1[0m" 415 -]
[2024-11-10 23:23:25,221: INFO: _internal: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.5:8080]
[2024-11-10 23:23:25,221: INFO: _internal: [33mPress CTRL+C to quit[0m]
[2024-11-10 23:23:56,851: INFO: _internal: 127.0.0.1 - - [10/Nov/2024 23:23:56] "[31m[1mPOST /predict HTTP/1.1[0m" 415 -]
